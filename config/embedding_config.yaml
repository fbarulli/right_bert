# config_embedding.yaml

# Top-level sections
training:
  seed: 42
  num_epochs: 1
  batch_size: 16 # DO NOT CHANGE
  debug_logging: true  # Enable debug logs for masking and other operations
  save_every_n_epochs: 1
  save_top_k: 3
  gradient_accumulation_steps: 2  # Increased to simulate larger batch size
  logging_steps: 100
  eval_steps: 200
  early_stopping_patience: 5
  early_stopping_min_delta: 0.001
  max_grad_norm: 1.0
  num_trials: 10
  n_jobs: 2
  n_startup_trials: 5
  study_name: "embedding_study"
  num_workers: 2
  fp16: true  # Use mixed precision training
  log_every_n_steps: 100
  optimizer_type: "adamw"  # Optimizer type (adamw, adam, sgd)
  learning_rate: 1.0e-4  # BERT's original learning rate
  weight_decay: 0.01  # Weight decay
  warmup_ratio: 0.1  # BERT's warmup ratio
  hidden_dropout_prob: 0.1  # Hidden dropout
  attention_probs_dropout_prob: 0.1  # Attention dropout

  # Scheduler settings
  scheduler:
    type: "linear"  # Linear decay like BERT
    warmup_ratio: 0.1  # Match training warmup
    min_lr_ratio: 0.0  # Decay to 0
    use_scheduler: true

data:
  csv_path: "sample_m.csv"  # do not change
  train_ratio: 0.8
  max_length: 512
  embedding_mask_probability: 0.15  # Standard BERT masking probability
  max_predictions: 20
  max_span_length: 3  # Allow 1-3 word spans for better context

model:
  name: "bert-base-uncased"
  type: "pretrained"
  stage: "embedding"

hyperparameters:
  learning_rate:
    type: "log"
    min: 1.0e-5
    max: 5.0e-5
  weight_decay:
    type: "float"
    min: 0.0
    max: 0.1
  warmup_ratio:
    type: "float"
    min: 0.0
    max: 0.2
  embedding_mask_probability:
    type: "float"
    min: 0.1
    max: 0.3
  max_span_length:
    type: "int"
    min: 1
    max: 5
  hidden_dropout_prob:
    type: "float"
    min: 0.0
    max: 0.3
  attention_probs_dropout_prob:
    type: "float"
    min: 0.0
    max: 0.3

# Resource limits
resources:
  max_memory_gb: 22.5  # DO NOT CHANGE
  gpu_memory_gb: 10.0  # Maximum GPU memory usage
  garbage_collection_threshold: 0.7
  max_split_size_mb: 2048
  max_time_hours: 24
  cache_cleanup_days: 7

output:
  dir: "outputs"
  save_model: true
  save_optimizer: false
  save_scheduler: false
